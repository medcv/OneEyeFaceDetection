# OneEye Face Recognition

Facial recognition is a biometric solution that measures unique characteristics about one’s face. Applications available today include flight checking, tagging friends and family members in photos, and “tailored” advertising.

As part of AWS DeepLens Challenge (#AWSDEEPLENS) we have implemented two use cases for face identification solution using DeepLens: First use case is Customer Identification. To satisfy the goal, we used customers’ profile pictures on a system (i.e., Bank) to match with DeepLens face detection results on real time basis when customer enters to a branch. Upon customer identification via DeepLens algorithm, an API call fetches customer's account details and surface the information on Bank's desktop web application. [Here](https://youtu.be/4WFmJTUzjTI) is a demo for customer identification.

Second use case is Amber Alert. We developed a mobile application that takes a picture of a missing person (or wanted person) and uploads it to storage back-end (AWS S3 in this case). As soon as image is uploaded, DeepLens uses this new picture in its face identification algorithm and identifies the person on real time video streaming. When missing person is detected, DeepLens sends a notification via email or phone, whichever is subscribed, to notify the authorities. Here is a demo for Amber Alert use case. [Here](https://youtu.be/zMAzF-suGXY) is a demo for Amber Alert use case.

## How I built it

Face recognition model is built using [dlib](http://dlib.net/)'s state-of-the-art face detection libraries. The model has an accuracy of 99.38% on the Labeled Faces in the Wild benchmark [1](https://github.com/ageitgey/face_recognition). 

Greengrass lambda function runs the face detection algorithm on the DeepLens device and publishes an event to the IOT topic as soon as it identifies a face. There exists another lambda function listening to this topic and fetches customer's info via API call from back-end's database. After data got retrived, this Lambda will publish an event to SNS with customers information as payload. A NodeJs web server (running on EC2) accepts the POST call from SNS and broadcasts a message to all of the clients (web or mobile) registered to it via WebSocket. This architecture allows real time update of the Client application as soon a new customers step into the branch. You can find more information about Customer Identification diagram [Here](https://github.com/medcv/OneEyeFaceDetection/blob/master/diagrams/CustomerIdentification.jpg) and Amber Alert diagram [Here](https://github.com/medcv/OneEyeFaceDetection/blob/master/diagrams/AmberAlert.jpg)

## Installation

### Requirements

  * Python 3.3+ or Python 2.7
  *  AWS DeepLens
### Installation Options:

#### Installing on DeepLens  (Linux)

First, make sure you have dlib already installed with Python bindings:

  * [How to install dlib from source on macOS or Ubuntu](https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf)

Then, install this module from pypi using `pip3` (or `pip2` for Python 2):

```bash
pip3 install face_recognition
```

#### Python Module

You can import the `face_recognition` module and then easily manipulate
faces with just a couple of lines of code. It's super easy!

API Docs: [https://face-recognition.readthedocs.io](https://face-recognition.readthedocs.io/en/latest/face_recognition.html).

##### Automatically find all the faces in an image

```python
import face_recognition

image = face_recognition.load_image_file("my_picture.jpg")
face_locations = face_recognition.face_locations(image)

# face_locations is now an array listing the co-ordinates of each face!
```

## Deployment 

You can deploy the code on DeepLens by follwing this [AWS documents](https://docs.aws.amazon.com/deeplens/latest/dg/deeplens-deploy-project.html). This will deploy the lambda function in this path on the device

 ```/opt/awscam/greengrass/ggc/deployment/lambda/arn:aws:lambda:<AWS_Region>:<Registration_Id>:function:deeplens-face-detection:<Version_Number>```

and will create a GreenGrass Group which you can find more info [HERE](https://docs.aws.amazon.com/greengrass/latest/developerguide/device-group.html)

For re-deploying the code after changes you can use this command
``` aws greengrass create-deployment --group-id <GG-GroupId> --deployment-type NewDeployment  --region <AWS-Region>  --group-version-id  <Group-Version-Id>```

## Debugging
When the code got deployed on the device, GreenGrass creates two log files; System log and User log
```
/opt/awscam/greengrass/ggc/var/log
    - crash.log
    - system
        - log files for each Greengrass system component
    - user
        - log files generated by each Lambda function
```

For more info read this [documents](https://docs.aws.amazon.com/greengrass/latest/developerguide/greengrass-logs-overview.html)


